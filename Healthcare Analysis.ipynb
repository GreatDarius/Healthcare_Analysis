{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will focus on healthcare. This data set is made available by MIT. It contains data about 9,026 heartbeat measurements. Each row represents a single measurement (captured on a timeline). There are a total of 80 data points (columns). This is a multiclass classification task: predict whether the measurement represents a normal heartbeat or other anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required packages\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "\n",
    "heart_data = pd.read_csv(\"heartbeat_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating Target variable from Input variables\n",
    "\n",
    "y = heart_data['Target']\n",
    "x = heart_data.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into test and train sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target variables need to be an array with integer type\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "train_y = train_y.astype(int)\n",
    "test_y = test_y.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert input variables to a 2-D array with float data type\n",
    "train_x= np.array(train_x)\n",
    "test_x= np.array(test_x)\n",
    "\n",
    "train_x = train_x.astype(np.float32)\n",
    "test_x = test_x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras expects a different input format:\n",
    "#Data needs to have 3 dimensions\n",
    "\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.582035\n",
       "4    0.198995\n",
       "2    0.155402\n",
       "1    0.055905\n",
       "3    0.007663\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data['Target'].value_counts()/len(heart_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The baseline shows the accuracy for each of our classifications from 0 to 4. As you can see the hieghest accuracy is for the first class with 58% accuracy. This means that our models should perform better than that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional shallow model using Keras (with only one hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing early stopping from tenserflow\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Flatten(input_shape=[80, 1]),\n",
    "    keras.layers.Dense(80, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.7622 - val_loss: 1.0298 - val_accuracy: 0.6286\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.8492 - val_loss: 0.4704 - val_accuracy: 0.8442\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.3881 - accuracy: 0.8859 - val_loss: 0.3980 - val_accuracy: 0.8681\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.9004 - val_loss: 0.3209 - val_accuracy: 0.9079\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.9051 - val_loss: 0.2996 - val_accuracy: 0.9100\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.3064 - accuracy: 0.9113 - val_loss: 1.4346 - val_accuracy: 0.7186\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.3063 - accuracy: 0.9121 - val_loss: 0.3875 - val_accuracy: 0.8760\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2793 - accuracy: 0.9164 - val_loss: 0.9556 - val_accuracy: 0.7642\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2855 - accuracy: 0.9148 - val_loss: 0.4486 - val_accuracy: 0.8434\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2682 - accuracy: 0.9192 - val_loss: 0.2733 - val_accuracy: 0.9255\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2530 - accuracy: 0.9246 - val_loss: 0.2752 - val_accuracy: 0.9192\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2537 - accuracy: 0.9209 - val_loss: 0.2631 - val_accuracy: 0.9209\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2368 - accuracy: 0.9304 - val_loss: 0.2476 - val_accuracy: 0.9234\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2341 - accuracy: 0.9298 - val_loss: 0.6012 - val_accuracy: 0.8224\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2346 - accuracy: 0.9289 - val_loss: 0.2382 - val_accuracy: 0.9305\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2244 - accuracy: 0.9314 - val_loss: 0.2833 - val_accuracy: 0.9175\n",
      "Epoch 17/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.9329 - val_loss: 0.2484 - val_accuracy: 0.9301\n",
      "Epoch 18/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.2112 - accuracy: 0.9354 - val_loss: 0.2276 - val_accuracy: 0.9372\n",
      "Epoch 19/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.2042 - accuracy: 0.9363 - val_loss: 0.2429 - val_accuracy: 0.9343\n",
      "Epoch 20/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.2064 - accuracy: 0.9361 - val_loss: 0.2413 - val_accuracy: 0.9313\n",
      "Epoch 21/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.9366 - val_loss: 0.2405 - val_accuracy: 0.9280\n",
      "Epoch 22/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1952 - accuracy: 0.9384 - val_loss: 0.4078 - val_accuracy: 0.8287\n",
      "Epoch 23/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2009 - accuracy: 0.9392 - val_loss: 0.2218 - val_accuracy: 0.9389\n",
      "Epoch 24/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1934 - accuracy: 0.9411 - val_loss: 0.2417 - val_accuracy: 0.9326\n",
      "Epoch 25/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1862 - accuracy: 0.9431 - val_loss: 0.2325 - val_accuracy: 0.9389\n",
      "Epoch 26/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1846 - accuracy: 0.9447 - val_loss: 0.2301 - val_accuracy: 0.9351\n",
      "Epoch 27/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1824 - accuracy: 0.9436 - val_loss: 0.5441 - val_accuracy: 0.7902\n",
      "Epoch 28/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1871 - accuracy: 0.9447 - val_loss: 0.2229 - val_accuracy: 0.9435\n",
      "Epoch 29/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1806 - accuracy: 0.9447 - val_loss: 0.2485 - val_accuracy: 0.9376\n",
      "Epoch 30/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1739 - accuracy: 0.9469 - val_loss: 0.2233 - val_accuracy: 0.9422\n",
      "Epoch 31/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9478 - val_loss: 0.2466 - val_accuracy: 0.9338\n",
      "Epoch 32/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1753 - accuracy: 0.9447 - val_loss: 0.2753 - val_accuracy: 0.9204\n",
      "Epoch 33/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1723 - accuracy: 0.9485 - val_loss: 0.2444 - val_accuracy: 0.9380\n",
      "Epoch 34/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1685 - accuracy: 0.9487 - val_loss: 0.2480 - val_accuracy: 0.9393\n",
      "Epoch 35/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1716 - accuracy: 0.9451 - val_loss: 0.2586 - val_accuracy: 0.9355\n",
      "Epoch 36/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1676 - accuracy: 0.9478 - val_loss: 0.2679 - val_accuracy: 0.9276\n",
      "Epoch 37/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1650 - accuracy: 0.9465 - val_loss: 0.2847 - val_accuracy: 0.9267\n",
      "Epoch 38/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1607 - accuracy: 0.9487 - val_loss: 0.2605 - val_accuracy: 0.9351\n",
      "Epoch 39/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1609 - accuracy: 0.9492 - val_loss: 0.2442 - val_accuracy: 0.9401\n",
      "Epoch 40/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1570 - accuracy: 0.9530 - val_loss: 0.3061 - val_accuracy: 0.9221\n",
      "Epoch 41/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1618 - accuracy: 0.9497 - val_loss: 0.2469 - val_accuracy: 0.9359\n",
      "Epoch 42/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1571 - accuracy: 0.9497 - val_loss: 0.2564 - val_accuracy: 0.9322\n",
      "Epoch 43/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1502 - accuracy: 0.9517 - val_loss: 0.2336 - val_accuracy: 0.9405\n",
      "Epoch 44/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1512 - accuracy: 0.9514 - val_loss: 0.2372 - val_accuracy: 0.9414\n",
      "Epoch 45/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1536 - accuracy: 0.9494 - val_loss: 0.2425 - val_accuracy: 0.9405\n",
      "Epoch 46/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1529 - accuracy: 0.9501 - val_loss: 0.2808 - val_accuracy: 0.9305\n",
      "Epoch 47/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1487 - accuracy: 0.9530 - val_loss: 0.2422 - val_accuracy: 0.9380\n",
      "Epoch 48/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9539 - val_loss: 0.2462 - val_accuracy: 0.9397\n",
      "Epoch 49/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1507 - accuracy: 0.9523 - val_loss: 0.2704 - val_accuracy: 0.9422\n",
      "Epoch 50/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1433 - accuracy: 0.9541 - val_loss: 0.5477 - val_accuracy: 0.8769\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                    validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5477070808410645, 0.876884400844574]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.55\n",
      "accuracy: 87.69%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our first model is shallow cross sectional with one hidden layer. this model accuracy is 93.72 percent using relu as hidden layers activation function and softmax as output layer activation function (Because our out put is multi class classification) which is almost 2 times better than the base line. we also used selu as activation function but the result was less accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional deep model using Keras (with two or more hidden layers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Flatten(input_shape=[80, 1]),\n",
    "    keras.layers.Dense(80, activation='relu'),\n",
    "    keras.layers.Dense(80, activation='relu'),\n",
    "    keras.layers.Dense(80, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 2s 4ms/step - loss: 0.7367 - accuracy: 0.7434 - val_loss: 1.0474 - val_accuracy: 0.6022\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.4698 - accuracy: 0.8388 - val_loss: 0.4152 - val_accuracy: 0.8647\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8726 - val_loss: 0.3335 - val_accuracy: 0.9016\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.3446 - accuracy: 0.8925 - val_loss: 0.3451 - val_accuracy: 0.8894\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.3153 - accuracy: 0.9042 - val_loss: 0.3223 - val_accuracy: 0.8924\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.3011 - accuracy: 0.9070 - val_loss: 0.5408 - val_accuracy: 0.8254\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2821 - accuracy: 0.9139 - val_loss: 0.3132 - val_accuracy: 0.8978\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2607 - accuracy: 0.9219 - val_loss: 1.0216 - val_accuracy: 0.7718\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.3156 - accuracy: 0.8930 - val_loss: 0.8304 - val_accuracy: 0.7684\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.3006 - accuracy: 0.9094 - val_loss: 0.2698 - val_accuracy: 0.9217\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2397 - accuracy: 0.9277 - val_loss: 0.3047 - val_accuracy: 0.9095\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2571 - accuracy: 0.9191 - val_loss: 0.2338 - val_accuracy: 0.9288\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2165 - accuracy: 0.9338 - val_loss: 0.3347 - val_accuracy: 0.8961\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2179 - accuracy: 0.9305 - val_loss: 0.2517 - val_accuracy: 0.9255\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2040 - accuracy: 0.9381 - val_loss: 0.2730 - val_accuracy: 0.9158\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1939 - accuracy: 0.9372 - val_loss: 0.3149 - val_accuracy: 0.9221\n",
      "Epoch 17/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1961 - accuracy: 0.9386 - val_loss: 0.2638 - val_accuracy: 0.9347\n",
      "Epoch 18/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1911 - accuracy: 0.9392 - val_loss: 0.2677 - val_accuracy: 0.9313\n",
      "Epoch 19/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1745 - accuracy: 0.9431 - val_loss: 0.2637 - val_accuracy: 0.9363\n",
      "Epoch 20/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2045 - accuracy: 0.9352 - val_loss: 0.2576 - val_accuracy: 0.9322\n",
      "Epoch 21/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1731 - accuracy: 0.9454 - val_loss: 0.2496 - val_accuracy: 0.9330\n",
      "Epoch 22/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1699 - accuracy: 0.9460 - val_loss: 0.4043 - val_accuracy: 0.8769\n",
      "Epoch 23/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1907 - accuracy: 0.9390 - val_loss: 0.2490 - val_accuracy: 0.9359\n",
      "Epoch 24/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1696 - accuracy: 0.9471 - val_loss: 0.2534 - val_accuracy: 0.9343\n",
      "Epoch 25/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1603 - accuracy: 0.9519 - val_loss: 0.2269 - val_accuracy: 0.9426\n",
      "Epoch 26/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1478 - accuracy: 0.9523 - val_loss: 0.2671 - val_accuracy: 0.9405\n",
      "Epoch 27/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1611 - accuracy: 0.9508 - val_loss: 0.2744 - val_accuracy: 0.9288\n",
      "Epoch 28/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1644 - accuracy: 0.9465 - val_loss: 0.2433 - val_accuracy: 0.9443\n",
      "Epoch 29/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1496 - accuracy: 0.9514 - val_loss: 0.2224 - val_accuracy: 0.9472\n",
      "Epoch 30/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1374 - accuracy: 0.9542 - val_loss: 0.2404 - val_accuracy: 0.9351\n",
      "Epoch 31/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1667 - accuracy: 0.9485 - val_loss: 0.2743 - val_accuracy: 0.9363\n",
      "Epoch 32/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1402 - accuracy: 0.9562 - val_loss: 0.2552 - val_accuracy: 0.9363\n",
      "Epoch 33/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1608 - accuracy: 0.9471 - val_loss: 0.2720 - val_accuracy: 0.9430\n",
      "Epoch 34/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1351 - accuracy: 0.9576 - val_loss: 0.2946 - val_accuracy: 0.9363\n",
      "Epoch 35/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1323 - accuracy: 0.9580 - val_loss: 0.2857 - val_accuracy: 0.9372\n",
      "Epoch 36/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1244 - accuracy: 0.9591 - val_loss: 0.2677 - val_accuracy: 0.9296\n",
      "Epoch 37/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1350 - accuracy: 0.9593 - val_loss: 0.3050 - val_accuracy: 0.9468\n",
      "Epoch 38/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1352 - accuracy: 0.9555 - val_loss: 0.3378 - val_accuracy: 0.9276\n",
      "Epoch 39/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1328 - accuracy: 0.9571 - val_loss: 0.2940 - val_accuracy: 0.9376\n",
      "Epoch 40/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1438 - accuracy: 0.9562 - val_loss: 0.3047 - val_accuracy: 0.9368\n",
      "Epoch 41/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1217 - accuracy: 0.9609 - val_loss: 0.2790 - val_accuracy: 0.9401\n",
      "Epoch 42/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1445 - accuracy: 0.9550 - val_loss: 0.3101 - val_accuracy: 0.9125\n",
      "Epoch 43/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1789 - accuracy: 0.9480 - val_loss: 0.2719 - val_accuracy: 0.9322\n",
      "Epoch 44/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1414 - accuracy: 0.9553 - val_loss: 0.2777 - val_accuracy: 0.9359\n",
      "Epoch 45/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1248 - accuracy: 0.9621 - val_loss: 0.2734 - val_accuracy: 0.9422\n",
      "Epoch 46/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1637 - accuracy: 0.9503 - val_loss: 0.2796 - val_accuracy: 0.9405\n",
      "Epoch 47/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1442 - accuracy: 0.9546 - val_loss: 0.2864 - val_accuracy: 0.9401\n",
      "Epoch 48/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1284 - accuracy: 0.9609 - val_loss: 0.2623 - val_accuracy: 0.9435\n",
      "Epoch 49/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1104 - accuracy: 0.9655 - val_loss: 0.2620 - val_accuracy: 0.9405\n",
      "Epoch 50/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1222 - accuracy: 0.9620 - val_loss: 0.3436 - val_accuracy: 0.9238\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                    validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3435995578765869, 0.9237855672836304]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.34\n",
      "accuracy: 92.38%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this model we used keras and build a model with 3 hidden layers and activation function of relu. The output layer is still softmax due to multi class classification. we increased the number of the hidden layers and get better results infact we got 94 percent accuracy which is a little bit better than model with one layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential shallow LSTM Model (with only one LSTM layer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "        keras.layers.LSTM(80, activation='softmax' , input_shape=[n_steps, n_inputs])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 15s 72ms/step - loss: 2.1384 - accuracy: 0.5698 - val_loss: 1.1784 - val_accuracy: 0.5490\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 14s 80ms/step - loss: 1.0816 - accuracy: 0.6023 - val_loss: 1.0799 - val_accuracy: 0.5586\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 14s 79ms/step - loss: 1.0576 - accuracy: 0.6019 - val_loss: 1.0614 - val_accuracy: 0.6219\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 13s 77ms/step - loss: 1.0354 - accuracy: 0.6136 - val_loss: 1.0585 - val_accuracy: 0.6214\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 14s 77ms/step - loss: 1.0185 - accuracy: 0.6280 - val_loss: 1.0175 - val_accuracy: 0.6244\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 13s 77ms/step - loss: 0.9906 - accuracy: 0.6441 - val_loss: 1.0070 - val_accuracy: 0.6080\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 13s 76ms/step - loss: 0.9713 - accuracy: 0.6455 - val_loss: 1.0176 - val_accuracy: 0.5666\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.9554 - accuracy: 0.6418 - val_loss: 0.9629 - val_accuracy: 0.6177\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 14s 79ms/step - loss: 0.9379 - accuracy: 0.6412 - val_loss: 1.1475 - val_accuracy: 0.4845\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 14s 78ms/step - loss: 0.9261 - accuracy: 0.6434 - val_loss: 0.9566 - val_accuracy: 0.6039\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - 14s 78ms/step - loss: 0.9043 - accuracy: 0.6430 - val_loss: 0.9137 - val_accuracy: 0.6206\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - 14s 80ms/step - loss: 0.8839 - accuracy: 0.6484 - val_loss: 0.8845 - val_accuracy: 0.6382\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - 12s 79ms/step - loss: 0.8620 - accuracy: 0.6613 - val_loss: 0.9053 - val_accuracy: 0.6323\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - 14s 78ms/step - loss: 0.8469 - accuracy: 0.6726 - val_loss: 0.9778 - val_accuracy: 0.6399\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - 14s 79ms/step - loss: 0.8351 - accuracy: 0.6755 - val_loss: 0.8897 - val_accuracy: 0.6595\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - 14s 79ms/step - loss: 0.8272 - accuracy: 0.6838 - val_loss: 0.8158 - val_accuracy: 0.6838\n",
      "Epoch 17/50\n",
      "175/175 [==============================] - 14s 77ms/step - loss: 0.8140 - accuracy: 0.6947 - val_loss: 0.8726 - val_accuracy: 0.6608\n",
      "Epoch 18/50\n",
      "175/175 [==============================] - 14s 77ms/step - loss: 0.8007 - accuracy: 0.7035 - val_loss: 0.8523 - val_accuracy: 0.6759\n",
      "Epoch 19/50\n",
      "175/175 [==============================] - 14s 77ms/step - loss: 0.7856 - accuracy: 0.7145 - val_loss: 0.7643 - val_accuracy: 0.7136\n",
      "Epoch 20/50\n",
      "175/175 [==============================] - 13s 77ms/step - loss: 0.7679 - accuracy: 0.7279 - val_loss: 0.9347 - val_accuracy: 0.6595\n",
      "Epoch 21/50\n",
      "175/175 [==============================] - 13s 77ms/step - loss: 0.7582 - accuracy: 0.7306 - val_loss: 0.7635 - val_accuracy: 0.7178\n",
      "Epoch 22/50\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.7431 - accuracy: 0.7333 - val_loss: 0.8498 - val_accuracy: 0.6968\n",
      "Epoch 23/50\n",
      "175/175 [==============================] - 13s 77ms/step - loss: 0.7478 - accuracy: 0.7285 - val_loss: 0.7066 - val_accuracy: 0.7345\n",
      "Epoch 24/50\n",
      "175/175 [==============================] - 13s 76ms/step - loss: 0.7214 - accuracy: 0.7398 - val_loss: 0.7045 - val_accuracy: 0.7437\n",
      "Epoch 25/50\n",
      "175/175 [==============================] - 13s 77ms/step - loss: 0.7079 - accuracy: 0.7471 - val_loss: 0.6826 - val_accuracy: 0.7408\n",
      "Epoch 26/50\n",
      "175/175 [==============================] - 13s 76ms/step - loss: 0.6962 - accuracy: 0.7568 - val_loss: 0.6624 - val_accuracy: 0.7797\n",
      "Epoch 27/50\n",
      "175/175 [==============================] - 13s 77ms/step - loss: 0.6810 - accuracy: 0.7717 - val_loss: 0.6579 - val_accuracy: 0.7831\n",
      "Epoch 28/50\n",
      "175/175 [==============================] - 13s 76ms/step - loss: 0.6692 - accuracy: 0.7823 - val_loss: 0.6897 - val_accuracy: 0.7776\n",
      "Epoch 29/50\n",
      "175/175 [==============================] - 13s 76ms/step - loss: 0.6604 - accuracy: 0.7877 - val_loss: 0.6424 - val_accuracy: 0.7722\n",
      "Epoch 30/50\n",
      "175/175 [==============================] - 13s 76ms/step - loss: 0.6537 - accuracy: 0.7895 - val_loss: 0.7153 - val_accuracy: 0.7508\n",
      "Epoch 31/50\n",
      "175/175 [==============================] - 13s 77ms/step - loss: 0.6486 - accuracy: 0.7931 - val_loss: 0.6282 - val_accuracy: 0.7877\n",
      "Epoch 32/50\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.6444 - accuracy: 0.7997 - val_loss: 0.9107 - val_accuracy: 0.6591\n",
      "Epoch 33/50\n",
      "175/175 [==============================] - 13s 77ms/step - loss: 0.6410 - accuracy: 0.8004 - val_loss: 0.6721 - val_accuracy: 0.7626\n",
      "Epoch 34/50\n",
      "175/175 [==============================] - 13s 76ms/step - loss: 0.6405 - accuracy: 0.7994 - val_loss: 0.7768 - val_accuracy: 0.7270\n",
      "Epoch 35/50\n",
      "175/175 [==============================] - 13s 76ms/step - loss: 0.6565 - accuracy: 0.7845 - val_loss: 0.6138 - val_accuracy: 0.8107\n",
      "Epoch 36/50\n",
      "175/175 [==============================] - 13s 76ms/step - loss: 0.6256 - accuracy: 0.8090 - val_loss: 0.7496 - val_accuracy: 0.7730\n",
      "Epoch 37/50\n",
      "175/175 [==============================] - 13s 77ms/step - loss: 0.6254 - accuracy: 0.8087 - val_loss: 0.6149 - val_accuracy: 0.8023\n",
      "Epoch 38/50\n",
      "175/175 [==============================] - 13s 76ms/step - loss: 0.6175 - accuracy: 0.8119 - val_loss: 0.6156 - val_accuracy: 0.7986\n",
      "Epoch 39/50\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.6212 - accuracy: 0.8125 - val_loss: 0.6201 - val_accuracy: 0.8191\n",
      "Epoch 40/50\n",
      "175/175 [==============================] - 157s 900ms/step - loss: 0.6180 - accuracy: 0.8123 - val_loss: 0.7649 - val_accuracy: 0.7349\n",
      "Epoch 40: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7649096250534058, 0.7349246144294739]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.76\n",
      "accuracy: 73.49%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In our LSTM model with only one layer we achieved the accuracy of 79 percent which is somehow better than base line but way worse than our previous models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential deep LSTM Model (with only two LSTM layers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(80, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.LSTM(80),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 25s 131ms/step - loss: 1.1360 - accuracy: 0.5824 - val_loss: 1.5904 - val_accuracy: 0.2044\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 22s 123ms/step - loss: 1.1016 - accuracy: 0.5896 - val_loss: 1.1585 - val_accuracy: 0.5691\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 23s 129ms/step - loss: 1.1294 - accuracy: 0.5876 - val_loss: 1.1567 - val_accuracy: 0.5691\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 23s 132ms/step - loss: 1.1272 - accuracy: 0.5876 - val_loss: 1.1861 - val_accuracy: 0.5691\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 1.1278 - accuracy: 0.5876 - val_loss: 1.1519 - val_accuracy: 0.5691\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 21s 119ms/step - loss: 1.1264 - accuracy: 0.5876 - val_loss: 1.1921 - val_accuracy: 0.5691\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 1.1263 - accuracy: 0.5876 - val_loss: 1.2104 - val_accuracy: 0.5691\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 1.1274 - accuracy: 0.5876 - val_loss: 1.1456 - val_accuracy: 0.5691\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 21s 123ms/step - loss: 1.1250 - accuracy: 0.5876 - val_loss: 1.2512 - val_accuracy: 0.2044\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 1.1271 - accuracy: 0.5851 - val_loss: 1.1582 - val_accuracy: 0.5691\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 1.1238 - accuracy: 0.5876 - val_loss: 1.1390 - val_accuracy: 0.5691\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 1.1245 - accuracy: 0.5876 - val_loss: 1.1510 - val_accuracy: 0.5691\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 1.1257 - accuracy: 0.5876 - val_loss: 1.1535 - val_accuracy: 0.5691\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - 21s 122ms/step - loss: 1.1249 - accuracy: 0.5876 - val_loss: 1.1484 - val_accuracy: 0.5691\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - 21s 122ms/step - loss: 1.1256 - accuracy: 0.5876 - val_loss: 1.1606 - val_accuracy: 0.5691\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - 21s 122ms/step - loss: 1.1255 - accuracy: 0.5876 - val_loss: 1.1577 - val_accuracy: 0.5691\n",
      "Epoch 16: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1576522588729858, 0.5690954923629761]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.16\n",
      "accuracy: 56.91%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By trying to add more hidden layers to LSTM model the accuracy dropped even further down to 58 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential shallow GRU Model (with only one GRU layer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(80, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 14s 58ms/step - loss: 1.0688 - accuracy: 0.6030 - val_loss: 1.1869 - val_accuracy: 0.5117\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 9s 54ms/step - loss: 0.8402 - accuracy: 0.6965 - val_loss: 0.6008 - val_accuracy: 0.7952\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 10s 56ms/step - loss: 0.6821 - accuracy: 0.7737 - val_loss: 0.7512 - val_accuracy: 0.7508\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 9s 54ms/step - loss: 0.5402 - accuracy: 0.8324 - val_loss: 0.4887 - val_accuracy: 0.8492\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 9s 53ms/step - loss: 0.4790 - accuracy: 0.8489 - val_loss: 0.4182 - val_accuracy: 0.8614\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 9s 52ms/step - loss: 0.4416 - accuracy: 0.8613 - val_loss: 0.5613 - val_accuracy: 0.8392\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 10s 54ms/step - loss: 0.4061 - accuracy: 0.8728 - val_loss: 0.4496 - val_accuracy: 0.8740\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 9s 54ms/step - loss: 0.3894 - accuracy: 0.8803 - val_loss: 0.5331 - val_accuracy: 0.8141\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 10s 55ms/step - loss: 0.3634 - accuracy: 0.8950 - val_loss: 0.3617 - val_accuracy: 0.8899\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 9s 54ms/step - loss: 0.3541 - accuracy: 0.8936 - val_loss: 0.3322 - val_accuracy: 0.9008\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - 9s 54ms/step - loss: 0.3361 - accuracy: 0.8959 - val_loss: 0.3503 - val_accuracy: 0.8756\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - 9s 53ms/step - loss: 0.3184 - accuracy: 0.9040 - val_loss: 0.3168 - val_accuracy: 0.9033\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - 9s 54ms/step - loss: 0.2993 - accuracy: 0.9085 - val_loss: 0.3048 - val_accuracy: 0.9070\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - 9s 53ms/step - loss: 0.2959 - accuracy: 0.9097 - val_loss: 0.5942 - val_accuracy: 0.8233\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - 10s 54ms/step - loss: 0.2923 - accuracy: 0.9117 - val_loss: 0.3025 - val_accuracy: 0.9104\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - 10s 55ms/step - loss: 0.2733 - accuracy: 0.9169 - val_loss: 0.3329 - val_accuracy: 0.8991\n",
      "Epoch 17/50\n",
      "175/175 [==============================] - 9s 53ms/step - loss: 0.2648 - accuracy: 0.9156 - val_loss: 0.2937 - val_accuracy: 0.9087\n",
      "Epoch 18/50\n",
      "175/175 [==============================] - 9s 52ms/step - loss: 0.2648 - accuracy: 0.9148 - val_loss: 0.2620 - val_accuracy: 0.9146\n",
      "Epoch 19/50\n",
      "175/175 [==============================] - 9s 51ms/step - loss: 0.2472 - accuracy: 0.9232 - val_loss: 0.4292 - val_accuracy: 0.8585\n",
      "Epoch 20/50\n",
      "175/175 [==============================] - 9s 53ms/step - loss: 0.2502 - accuracy: 0.9200 - val_loss: 0.2519 - val_accuracy: 0.9225\n",
      "Epoch 21/50\n",
      "175/175 [==============================] - 9s 52ms/step - loss: 0.2546 - accuracy: 0.9173 - val_loss: 0.2864 - val_accuracy: 0.9100\n",
      "Epoch 22/50\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.2472 - accuracy: 0.9210 - val_loss: 0.3388 - val_accuracy: 0.8748\n",
      "Epoch 23/50\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.2319 - accuracy: 0.9257 - val_loss: 0.2638 - val_accuracy: 0.9209\n",
      "Epoch 24/50\n",
      "175/175 [==============================] - 10s 56ms/step - loss: 0.2393 - accuracy: 0.9235 - val_loss: 0.2538 - val_accuracy: 0.9183\n",
      "Epoch 25/50\n",
      "175/175 [==============================] - 10s 56ms/step - loss: 0.2309 - accuracy: 0.9259 - val_loss: 0.2589 - val_accuracy: 0.9217\n",
      "Epoch 25: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25891128182411194, 0.9216917753219604]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.26\n",
      "accuracy: 92.17%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In our GRU model with only one layer the accuracy is 91 percent which is better than baseline and LSTM with one layer but still not as good as first two models. By increasing the nuber of epochs model performed wose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential deep GRU Model (with only two GRU layers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(80, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(80),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 28s 118ms/step - loss: 0.9729 - accuracy: 0.6405 - val_loss: 1.2436 - val_accuracy: 0.4920\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 18s 104ms/step - loss: 0.4995 - accuracy: 0.8413 - val_loss: 0.7619 - val_accuracy: 0.7688\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 18s 105ms/step - loss: 0.3866 - accuracy: 0.8810 - val_loss: 0.3334 - val_accuracy: 0.8961\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 19s 107ms/step - loss: 0.3773 - accuracy: 0.8841 - val_loss: 0.2998 - val_accuracy: 0.9020\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 19s 108ms/step - loss: 0.3062 - accuracy: 0.9056 - val_loss: 0.3126 - val_accuracy: 0.9016\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 19s 106ms/step - loss: 0.2691 - accuracy: 0.9162 - val_loss: 1.1549 - val_accuracy: 0.7425\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 19s 109ms/step - loss: 0.2980 - accuracy: 0.9058 - val_loss: 0.3253 - val_accuracy: 0.8982\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 19s 107ms/step - loss: 0.2561 - accuracy: 0.9180 - val_loss: 0.2952 - val_accuracy: 0.9054\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 19s 111ms/step - loss: 0.2330 - accuracy: 0.9268 - val_loss: 0.3294 - val_accuracy: 0.9079\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 19s 109ms/step - loss: 0.5446 - accuracy: 0.8500 - val_loss: 1.5649 - val_accuracy: 0.6457\n",
      "Epoch 11/50\n",
      "145/175 [=======================>......] - ETA: 2s - loss: 0.7619 - accuracy: 0.7341"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By adding one more hidden layer to the model the GRU it doesn't performs better even though it takes longer to process. the accuracy of 84 % . By increasing the nuber of epochs model performed abit better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List the test values of each model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A cross-sectional shallow model (with only one hidden layer):\n",
    "                loss: 0.22\n",
    "                accuracy: 93.89%\n",
    "\n",
    "A cross-sectional deep model (with two or more hidden layers):\n",
    "                loss: 0.28\n",
    "                accuracy: 94.05%\n",
    "                \n",
    "A sequential shallow LSTM Model (with only one LSTM layer):\n",
    "                loss: 0.63\n",
    "                accuracy: 79.61%\n",
    "                \n",
    "A sequential deep LSTM Model (with only two LSTM layers):\n",
    "                loss: 1.11\n",
    "                accuracy: 59.30% \n",
    "                \n",
    "A sequential shallow GRU Model (with only one GRU layer):\n",
    "                loss: 0.40\n",
    "                accuracy: 85.97%\n",
    "\n",
    "A sequential deep GRU Model (with only two GRU layers):\n",
    "                loss: 0.48\n",
    "                accuracy: 84.55%\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
